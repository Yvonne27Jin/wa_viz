---
title: "wa_nlp"
author: "Yvonne"
date: "9/26/2024"
output: html_document
---

```{r}

# history <- system.file("extdata", "sample.txt", package = "rwhatsapp")


#chat <- rwa_read(history)
#chat
```

```{r}
library("rwhatsapp")
library("dplyr")
library("tidyr")
library("ggplot2"); theme_set(theme_minimal())
library("lubridate")

chat_Y <- rwa_read("_chat_st_202409.txt") %>% 
  filter(!is.na(author)) # remove messages without author
head(chat_Y)

df_processed <- chat_Y %>%
  # Convert time to Date format
  mutate(date = as.Date(time)) %>%
  # Count messages per date and author
  group_by(date, author) %>%
  summarise(n_messages = n()) %>%
  ungroup()

ggplot(df_processed, aes(x = date, y = n_messages, fill = author)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(x = "Date", y = "Number of Messages", title = "Messages Per Day by Author") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%Y") +  # Add labels for each month
  theme(axis.text.x = element_text(angle = 45, hjust = 1))        # Rotate x-axis labels

```



```{r}
# msg by person
# chat_Y %>%
#   mutate(day = date(time)) %>%
#   count(author) %>%
#   ggplot(aes(x = reorder(author, n), y = n)) +
#   geom_bar(stat = "identity") +
#   ylab("") + xlab("") +
#   coord_flip() +
#   ggtitle("Number of messages")

# 
# # Plot the data as a percentage (bars are the same height)
# ggplot(df_processed, aes(x = date, y = n_messages, fill = author)) +
#   geom_bar(stat = "identity", position = "fill") +  # Normalize to percentages
#   labs(x = "Date", y = "Percentage of Messages", title = "Percentage of Messages Per Day by Author") +
#   theme_minimal() +
#   scale_x_date(date_breaks = "1 month", date_labels = "%b-%Y") +  # Add labels for each month
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))        # Rotate x-axis labels
```

```{r eval=FALSE, include=FALSE}
# Data processing
df_processed_week <- chat_Y %>%
  # Convert time to Date format
  mutate(date = as.Date(time)) %>%
  # Group by weekly intervals
  mutate(week = cut.Date(date, breaks = "week", start.on.monday = TRUE)) %>%
  # Count messages per week and author
  group_by(week, author) %>%
  summarise(n_messages = n()) %>%
  ungroup()

# Plot the data grouped by week as a percentage (bars are the same height)
ggplot(df_processed_week, aes(x = week, y = n_messages, fill = author)) +
  geom_bar(stat = "identity", position = "fill") +  # Normalize to percentages
  labs(x = "Week", y = "Percentage of Messages", title = "Percentage of Messages Per Week by Author") +
  theme_minimal()  +
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%Y") +  # Add labels for each month
  theme(axis.text.x = element_text(angle = 45, hjust = 1))        # Rotate x-axis labels

ggplot(df_processed, aes(x = date, y = n_messages, fill = author)) +
  geom_bar(stat = "identity", position = "fill") +
  labs(x = "Date", y = "Number of Messages", title = "Messages Per Day by Author") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%Y") +  # Add labels for each month
  theme(axis.text.x = element_text(angle = 45, hjust = 1))        # Rotate x-axis labels
```

```{r}
# Data processing
df_processed <- chat_Y %>%
  # Convert time to Date format
  mutate(date = as.Date(time)) %>%
  # Group by weekly intervals
  mutate(week = as.Date(cut.Date(date, breaks = "week", start.on.monday = TRUE))) %>%
  # Count messages per week and author
  group_by(week, author) %>%
  summarise(n_messages = n()) %>%
  ungroup()

# Plot the data grouped by week as a percentage (bars are the same height)
ggplot(df_processed, aes(x = week, y = n_messages, fill = author)) +
  geom_bar(stat = "identity", position = "fill") +  # Normalize to percentages
  labs(x = "Week", y = "Percentage of Messages", title = "Percentage of Messages Per Week by Author") +
  theme_minimal() +
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%Y") +  # Now using scale_x_date since week is date type
  theme(axis.text.x = element_text(angle = 45, hjust = 1))        # Rotate x-axis labels
```


```{r eval=FALSE, include=FALSE}
# emoji

chat_Y %>%
  unnest(emoji) %>%
  count(author, emoji, sort = TRUE) %>%
  group_by(author) %>%
  top_n(n = 6, n) %>%
  ggplot(aes(x = reorder(emoji, n), y = n, fill = author)) +
  geom_col(show.legend = FALSE) +
  ylab("") +
  xlab("") +
  coord_flip() +
  facet_wrap(~author, ncol = 2, scales = "free_y")  +
  ggtitle("Most often used emojis")
# can't display emoji in plot, use anotehr database
```

```{r}
library("ggimage")
emoji_data <- rwhatsapp::emojis %>% # data built into package
  mutate(hex_runes1 = gsub("\\s.*", "", hex_runes)) %>% # ignore combined emojis
  mutate(emoji_url = paste0("https://abs.twimg.com/emoji/v2/72x72/", 
                            tolower(hex_runes1), ".png"))

chat_Y %>%
  unnest(emoji) %>%
  count(author, emoji, sort = TRUE) %>%
  group_by(author) %>%
  top_n(n = 6, n) %>%
  left_join(emoji_data, by = "emoji") %>% 
  ggplot(aes(x = reorder(emoji, n), y = n, fill = author)) +
  geom_col(show.legend = FALSE) +
  ylab("") +
  xlab("") +
  coord_flip() +
  geom_image(aes(y = n + 20, image = emoji_url)) +
  facet_wrap(~author, ncol = 2, scales = "free_y") +
  ggtitle("Most often used emojis") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```


```{r eval=FALSE, include=FALSE}
# text analysis

# Traditional-Simplified Chinese conversion

# Chinese stopwords and preprocessing databases
??stopwords
#This function returns character vectors of stopwords for different languages, 
#using the ISO-639-1 language codes, and allows for different sources of stopwords to be defined.
library("stopwords")
library("tidytext")
stopwords_getsources()
# set language for stopwords to Chinese
to_remove <- c(stopwords(language = "zh", source = "misc"),
               "media",
               "omitted",
               "ref",
               "dass",
               "schon",
               "mal",
               "android.s.wt")

chat_Y %>%
  unnest_tokens(input = text,
                output = word) %>%
  filter(!word %in% to_remove) %>%
  count(author, word, sort = TRUE) %>%
  group_by(author) %>%
  top_n(n = 6, n) %>%
  ggplot(aes(x = reorder_within(word, n, author), y = n, fill = author)) +
  geom_col(show.legend = FALSE) +
  ylab("") +
  xlab("") +
  coord_flip() +
  facet_wrap(~author, ncol = 2, scales = "free_y") +
  scale_x_reordered() +
  ggtitle("Most often used words")
```

```{r eval=FALSE, include=FALSE}
# need cleaning up 
#using the ISO-639-1 language codes, and allows for different sources of stopwords to be defined.
library("stopwords")
library("tidytext")


# lexical diversity

chat_Y %>%
  unnest_tokens(input = text,
                output = word) %>%
  filter(!word %in% to_remove) %>%
  group_by(author) %>%
  summarise(lex_diversity = n_distinct(word)) %>%
  arrange(desc(lex_diversity)) %>%
  ggplot(aes(x = reorder(author, lex_diversity),
             y = lex_diversity,
             fill = author)) +
  geom_col(show.legend = FALSE) +
  scale_y_continuous(expand = (mult = c(0, 0, 0, 500))) +
  geom_text(aes(label = scales::comma(lex_diversity)), hjust = -0.1) +
  ylab("unique words") +
  xlab("") +
  ggtitle("Lexical Diversity") +
  coord_flip()

```

```{r eval=FALSE, include=FALSE}
# relative unique words

o_words <- chat_Y %>%
  unnest_tokens(input = text,
                output = word) %>%
  filter(author != "Yvonne Jin") %>% 
  count(word, sort = TRUE) 

chat_Y %>%
  unnest_tokens(input = text,
                output = word) %>%
  filter(author == "Yvonne Jin") %>% 
  count(word, sort = TRUE) %>% 
  filter(!word %in% o_words$word) %>% # only select words nobody else uses
  top_n(n = 6, n) %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(show.legend = FALSE) +
  ylab("") + xlab("") +
  coord_flip() +
  ggtitle("Unique words of Yvonne")
# Need cleaning up


```

